version: "1"
services:
  docs:
    container_name: docs
    image: nginx
    ports:
      - "80:80"
    volumes:
      - "./nginx/html:/usr/share/nginx/html:ro"

  master:
    container_name: master
    image: arjones/pyspark:2.4.5
    restart: always
    command: ["/opt/spark/sbin/start-master.sh"]
    environment:
      MASTER: spark://master:7077
      SPARK_NO_DAEMONIZE: 1
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080
    volumes:
      - ./code:/app
      - ./dataset:/dataset

  worker1:
    container_name: worker1
    image: arjones/pyspark:2.4.5
    restart: always
    command: ["/opt/spark/sbin/start-slave.sh", "spark://master:7077"]
    environment:
      MASTER: spark://master:7077
      SPARK_NO_DAEMONIZE: 1
    depends_on:
      - master
    ports:
      - 4041:4040
      - "6066"
      - "7077"
      - 8081:8080
    volumes:
      - ./code:/app
      - ./dataset:/dataset

  worker2:
    container_name: worker2
    image: arjones/pyspark:2.4.5
    restart: always
    command: ["/opt/spark/sbin/start-slave.sh", "spark://master:7077"]
    environment:
      MASTER: spark://master:7077
      SPARK_NO_DAEMONIZE: 1
    depends_on:
      - master
    ports:
      - 4042:4040
      - "6066"
      - "7077"
      - 8082:8080
    volumes:
      - ./code:/app
      - ./dataset:/dataset

  jupyter:
    container_name: jupyter
    image: arjones/pyspark:2.4.5
    restart: always
    environment:
      MASTER: spark://master:7077
    depends_on:
      - master
    ports:
      - "8888:8888"
    volumes:
      - ./src/notebook:/notebook
      - ./src/utils:/utils
      - ./dataset:/dataset
